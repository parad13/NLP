{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Chatbot_using_nltk.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parad13/NLP/blob/main/Chatbot_using_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzJVWEdgoGiY"
      },
      "source": [
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YJj072goGim",
        "outputId": "c95d9200-c304-4ceb-cabd-48fcc2ebd07c"
      },
      "source": [
        "Chat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.chat.util.Chat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v-uB55toGip",
        "outputId": "77f88b9c-8297-41d4-f1b9-9108635fd37c"
      },
      "source": [
        "reflections"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'i am': 'you are',\n",
              " 'i was': 'you were',\n",
              " 'i': 'you',\n",
              " \"i'm\": 'you are',\n",
              " \"i'd\": 'you would',\n",
              " \"i've\": 'you have',\n",
              " \"i'll\": 'you will',\n",
              " 'my': 'your',\n",
              " 'you are': 'I am',\n",
              " 'you were': 'I was',\n",
              " \"you've\": 'I have',\n",
              " \"you'll\": 'I will',\n",
              " 'your': 'my',\n",
              " 'yours': 'mine',\n",
              " 'you': 'me',\n",
              " 'me': 'you'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKeN9WnUoGir"
      },
      "source": [
        "#set of rules\n",
        "set_pairs = [\n",
        "    [\n",
        "        r\"my name is (.*)\",\n",
        "        [\"Hello %1, How are you doing today ?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"hi|hey|hello\",\n",
        "        [\"Hello\", \"Hey there\",]\n",
        "    ], \n",
        "    [\n",
        "        r\"what is your name?\",\n",
        "        [\"You can call me a chatbot ?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"how are you ?\",\n",
        "        [\"I am fine, thank you! How can i help you?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"I am fine, thank you\",\n",
        "        [\"great to hear that, how can i help you?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"how can i help you? \",\n",
        "        [\"i am looking for online guides and courses to learn data science, can you suggest?\", \"i am looking for data science training platforms\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"i'm (.*) doing good\",\n",
        "        [\"That's great to hear\",\"How can i help you?:)\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"i am looking for online guides and courses to learn data science, can you suggest?\",\n",
        "        [\"Pluralsight is a great option to learn data science. You can check their website\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"thanks for the suggestion. do they have great authors and instructors?\",\n",
        "        [\"Yes, they have the world class best authors, that is their strength;)\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) thank you so much, that was helpful\",\n",
        "        [\"Iam happy to help\", \"No problem, you're welcome\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"quit\",\n",
        "    [\"Bye, take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
        "],\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfoRjpmEoGis",
        "outputId": "f3656998-0514-4961-a03a-5e07fe5242e4"
      },
      "source": [
        "set_pairs[1:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hi|hey|hello', ['Hello', 'Hey there']],\n",
              " ['what is your name?', ['You can call me a chatbot ?']],\n",
              " ['how are you ?', ['I am fine, thank you! How can i help you?']],\n",
              " ['I am fine, thank you', ['great to hear that, how can i help you?']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5cCHMFNoGiv",
        "outputId": "e99b6ae9-0070-4ea1-b186-32bf3ae3a3cb"
      },
      "source": [
        "def chatbot():\n",
        "        print(\"Hi, I'm the chatbot you built\") \n",
        "\n",
        "chatbot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm the chatbot you built\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_a6dDDoGiw",
        "outputId": "63399ba4-46ea-4bf2-a31d-4d918f9e55a6"
      },
      "source": [
        "chat = Chat(set_pairs, reflections)\n",
        "print(chat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<nltk.chat.util.Chat object at 0x000002ADC8D1D0C8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cCY0ZJHoGiy",
        "outputId": "b2a5d6e1-af7c-419c-b6ff-0396c3cee872"
      },
      "source": [
        "chat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.chat.util.Chat at 0x2adc8d1d0c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeDS_sAtoGiz"
      },
      "source": [
        "chat.converse()\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCrQPnPYoGi0",
        "outputId": "6ee83b0d-6cf2-4c01-c383-421f9b69f2cd"
      },
      "source": [
        "# !pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: h5py in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
            "Requirement already satisfied: six in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\bakul waral\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek_b9pi_oGi0"
      },
      "source": [
        "## Another Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUv51T23oGi1",
        "outputId": "101c9786-0bef-464b-e2b8-e66f61395144"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD\n",
        "import random\n",
        "\n",
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "data_file = open('intents.json').read()\n",
        "intents = json.loads(data_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\bakul waral\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-5093d35fe280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO8s_6f-oGi2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}